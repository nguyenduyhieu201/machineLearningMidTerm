{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLMidTerm.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPTvIQwsZK+ogTdheQU6Wpk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyenduyhieu201/machineLearningMidTerm/blob/main/MLMidTerm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0-VP1W_Yn8M",
        "outputId": "cfe62eb1-b904-4685-d6e2-b1e918146dfb"
      },
      "source": [
        "!ls /content/drive/MyDrive/Colab\\ Notebooks/MLMidTerm.ipynb"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Bản sao của Colaboratory chào mừng bạn!'   MLMidTerm.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aE-BuxPJXrI-",
        "outputId": "8313671c-8a9f-40b2-efe2-821d0ed5ec55"
      },
      "source": [
        "!git init\n",
        "!git remote add origin https://github.com/nguyenduyhieu201/machineLearningMidTerm.git\n",
        "!git config --global user.email \"nguyenduyhieu202@gmail.com\"\n",
        "!git config --global user.name \"Hieu\"\n",
        "!git add /content/drive/MyDrive/Colab\\ Notebooks/MLMidTerm.ipynb\n",
        "!git commit -m \"Initial commit\"\n",
        "!git branch -M main\n",
        "!git push -u origin main"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/.git/\n",
            "fatal: remote origin already exists.\n",
            "[master (root-commit) 96825d2] Initial commit\n",
            " 1 file changed, 1 insertion(+)\n",
            " create mode 100644 drive/MyDrive/Colab Notebooks/MLMidTerm.ipynb\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5381msrBlR8c",
        "outputId": "20b48de1-f00e-4d16-dbf4-f96bd182919a"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "\n",
        "import torch.nn as nn\n",
        " \n",
        "input_path = \"../content/DATA_CHAMBER_2021/\"\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print(\"Using CUDA\")\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0m0b3Alokn5",
        "outputId": "4ca8e032-7d05-4b71-e0c7-7690c4976c85"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1RxJj9MpAW2"
      },
      "source": [
        "!unzip -uq \"/content/drive/My Drive/DATA_CHAMBER_2021.zip\" -d \"./\""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbnNsmk8pEOh"
      },
      "source": [
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dKqlll6pFTB"
      },
      "source": [
        "def data_transform(size):\n",
        "  data_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size),\n",
        "        transforms.CenterCrop(size),\n",
        "#         transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
        "#         transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'validation':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize(size),\n",
        "        transforms.CenterCrop(size),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    }\n",
        "  return data_transforms"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHHvqXprpLZ2"
      },
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "\n",
        "image_datasets = {\n",
        "    'train': \n",
        "    ImageFolderWithPaths(input_path + 'train', data_transform(224)['train']),\n",
        "    'validation': \n",
        "    ImageFolderWithPaths(input_path + 'test', data_transform(224)['validation'])\n",
        "}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train','validation']}\n",
        "\n",
        "dataloaders = {\n",
        "    'train':\n",
        "    torch.utils.data.DataLoader(image_datasets['train'],\n",
        "                                batch_size=8,\n",
        "                                shuffle=True,\n",
        "                                num_workers=2),\n",
        "    'validation':\n",
        "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
        "                                batch_size=8,\n",
        "                                shuffle=True,\n",
        "                                num_workers=2)\n",
        "}\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMQsqffYvpNm",
        "outputId": "37b989a3-c771-4f17-ddae-1793058ed92f"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NABWDU6pvqxU",
        "outputId": "bf087111-49cd-4341-bd15-ceee78b29ecf"
      },
      "source": [
        "!pip install efficientnet_pytorch "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu4EPkRIwBl4"
      },
      "source": [
        "modelResnet50 = models.resnet50(pretrained = True).cuda()\n",
        "for param in modelResnet50.parameters():\n",
        "    param.requires_grad = False           \n",
        "modelResnet50.fc = nn.Sequential(\n",
        "              nn.Linear(2048, 128),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.Linear(128, 3)).to(device)\n",
        "    \n",
        "modelVgg16 = models.vgg16_bn(pretrained = True).cuda()\n",
        "for param in modelVgg16.parameters():\n",
        "  param.requires_grad = False\n",
        "num_features = modelVgg16.classifier[6].in_features\n",
        "modelVgg16.classifier[6] = nn.Linear(4096, 3).to(device)\n",
        "\n",
        "modelResnet18 = models.resnet18(pretrained = True).cuda()\n",
        "for param in modelResnet18.parameters():\n",
        "    param.requires_grad = False           \n",
        "modelResnet18.fc = nn.Sequential(\n",
        "              nn.Linear(512, 128),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.Linear(128, 3)).to(device)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG0b0iVtwDt3"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizerResnet50 = optim.SGD(modelResnet50.fc.parameters(),lr=0.001,momentum=0.9)\n",
        "optimizerVgg16 = optim.SGD(modelVgg16.parameters(),lr=1,momentum=0.9)\n",
        "optimizerResnet18 = optim.SGD(modelResnet18.fc.parameters(),lr=0.001,momentum=0.9)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_-qi7gkwGtP"
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=3):\n",
        "    train_batches = len(dataloaders['train'])\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for i,data in enumerate(dataloaders[phase]):\n",
        "                inputs, labels,_ = data\n",
        "                print(\"\\rTraining batch {}/{}\".format(i+1, train_batches), end='', flush=True)\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(image_datasets[phase])\n",
        "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "\n",
        "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
        "                                                        epoch_loss,\n",
        "                                                        epoch_acc))\n",
        "    return model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijNX010GwIyU",
        "outputId": "267f2bfb-21bc-46fc-e8a8-2e351977f1b2"
      },
      "source": [
        "model_trained_resnet50 = train_model(modelResnet50, criterion, optimizerResnet50, num_epochs=20)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.6287, acc: 0.7398\n",
            "Epoch 2/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.5228, acc: 0.7902\n",
            "Epoch 3/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.4565, acc: 0.8121\n",
            "Epoch 4/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.4373, acc: 0.8218\n",
            "Epoch 5/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.3668, acc: 0.8587\n",
            "Epoch 6/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.3205, acc: 0.8732\n",
            "Epoch 7/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2929, acc: 0.8833\n",
            "Epoch 8/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2795, acc: 0.8919\n",
            "Epoch 9/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2473, acc: 0.9061\n",
            "Epoch 10/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2197, acc: 0.9180\n",
            "Epoch 11/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2002, acc: 0.9235\n",
            "Epoch 12/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1905, acc: 0.9308\n",
            "Epoch 13/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1714, acc: 0.9406\n",
            "Epoch 14/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1615, acc: 0.9404\n",
            "Epoch 15/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1507, acc: 0.9477\n",
            "Epoch 16/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1503, acc: 0.9458\n",
            "Epoch 17/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1342, acc: 0.9530\n",
            "Epoch 18/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1258, acc: 0.9536\n",
            "Epoch 19/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1169, acc: 0.9585\n",
            "Epoch 20/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1141, acc: 0.9592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nsNfjXlwJry",
        "outputId": "16cae24c-1412-4531-ddcd-db37ee72fdc6"
      },
      "source": [
        "model_trained_resnet18 = train_model(modelResnet18, criterion, optimizerResnet18, num_epochs=20)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.4025, acc: 0.8455\n",
            "Epoch 2/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.3199, acc: 0.8800\n",
            "Epoch 3/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2736, acc: 0.8988\n",
            "Epoch 4/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2353, acc: 0.9134\n",
            "Epoch 5/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.2205, acc: 0.9183\n",
            "Epoch 6/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1704, acc: 0.9428\n",
            "Epoch 7/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1511, acc: 0.9479\n",
            "Epoch 8/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1308, acc: 0.9595\n",
            "Epoch 9/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.1122, acc: 0.9601\n",
            "Epoch 10/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0988, acc: 0.9708\n",
            "Epoch 11/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0955, acc: 0.9644\n",
            "Epoch 12/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0882, acc: 0.9698\n",
            "Epoch 13/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0897, acc: 0.9708\n",
            "Epoch 14/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0697, acc: 0.9784\n",
            "Epoch 15/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0601, acc: 0.9818\n",
            "Epoch 16/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0589, acc: 0.9806\n",
            "Epoch 17/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0555, acc: 0.9812\n",
            "Epoch 18/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0521, acc: 0.9838\n",
            "Epoch 19/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0501, acc: 0.9854\n",
            "Epoch 20/20\n",
            "----------\n",
            "Training batch 840/840train loss: 0.0442, acc: 0.9865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItD8OEWwwLEA",
        "outputId": "0c631027-6178-4a9c-d5d4-e5ebf34c97bb"
      },
      "source": [
        "model_trained_vgg16 = train_model(modelVgg16, criterion, optimizerVgg16, num_epochs=20)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "----------\n",
            "Training batch 840/840train loss: 260.8878, acc: 0.5960\n",
            "Epoch 2/20\n",
            "----------\n",
            "Training batch 840/840train loss: 280.4682, acc: 0.6531\n",
            "Epoch 3/20\n",
            "----------\n",
            "Training batch 840/840train loss: 313.6347, acc: 0.6649\n",
            "Epoch 4/20\n",
            "----------\n",
            "Training batch 840/840train loss: 282.5340, acc: 0.6926\n",
            "Epoch 5/20\n",
            "----------\n",
            "Training batch 840/840train loss: 307.3144, acc: 0.6878\n",
            "Epoch 6/20\n",
            "----------\n",
            "Training batch 840/840train loss: 289.6958, acc: 0.7005\n",
            "Epoch 7/20\n",
            "----------\n",
            "Training batch 840/840train loss: 303.8634, acc: 0.7042\n",
            "Epoch 8/20\n",
            "----------\n",
            "Training batch 840/840train loss: 307.9463, acc: 0.7024\n",
            "Epoch 9/20\n",
            "----------\n",
            "Training batch 840/840train loss: 292.2456, acc: 0.7155\n",
            "Epoch 10/20\n",
            "----------\n",
            "Training batch 840/840train loss: 277.3496, acc: 0.7292\n",
            "Epoch 11/20\n",
            "----------\n",
            "Training batch 840/840train loss: 296.3367, acc: 0.7201\n",
            "Epoch 12/20\n",
            "----------\n",
            "Training batch 840/840train loss: 305.3337, acc: 0.7216\n",
            "Epoch 13/20\n",
            "----------\n",
            "Training batch 840/840train loss: 289.6910, acc: 0.7267\n",
            "Epoch 14/20\n",
            "----------\n",
            "Training batch 840/840train loss: 299.5734, acc: 0.7299\n",
            "Epoch 15/20\n",
            "----------\n",
            "Training batch 840/840train loss: 297.9494, acc: 0.7261\n",
            "Epoch 16/20\n",
            "----------\n",
            "Training batch 840/840train loss: 340.2770, acc: 0.7148\n",
            "Epoch 17/20\n",
            "----------\n",
            "Training batch 840/840train loss: 302.4147, acc: 0.7301\n",
            "Epoch 18/20\n",
            "----------\n",
            "Training batch 840/840train loss: 305.2081, acc: 0.7220\n",
            "Epoch 19/20\n",
            "----------\n",
            "Training batch 840/840train loss: 323.2935, acc: 0.7162\n",
            "Epoch 20/20\n",
            "----------\n",
            "Training batch 840/840train loss: 298.1153, acc: 0.7296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9lPeJmmwPM3"
      },
      "source": [
        "def test_model(model, criterion, optimizer):\n",
        "    labels_input=list()\n",
        "    labels_output=list()\n",
        "    vid_id = list()\n",
        "    for phase in ['validation']:\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels, fname in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            labels_input= labels_input + labels.tolist()\n",
        "            for f in fname:\n",
        "                vid_id.append(f.split('/')[-1].split('.')[0].split('_')[0])\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            labels_output= labels_output + preds.tolist()\n",
        "    return labels_input,labels_output,vid_id\n",
        "resnet50_y_true,resnet50_y_pred,resnet50_vid_id = test_model(modelResnet50, criterion, optimizerResnet50)\n",
        "resnet18_y_true,resnet18_y_pred,resnet18_vid_id = test_model(modelResnet18, criterion, optimizerResnet18)\n",
        "vgg16_y_true,vgg16_y_pred,vgg16_vid_id = test_model(modelVgg16, criterion, optimizerVgg16)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1T8MQ8twZxO",
        "outputId": "7b90fe2d-1b53-4453-a27c-2a24a32cc30e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
        "print(classification_report(resnet50_y_true,resnet50_y_pred))\n",
        "print(classification_report(resnet18_y_true,resnet18_y_pred))\n",
        "print(classification_report(vgg16_y_true,vgg16_y_pred))\n",
        "print('resnet 50 acc: ', accuracy_score(resnet50_y_true,resnet50_y_pred))\n",
        "print('resnet 18 acc: ', accuracy_score(resnet18_y_true,resnet18_y_pred))\n",
        "print('vgg16 acc: ', accuracy_score(vgg16_y_true,vgg16_y_pred))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.61      0.65       409\n",
            "           1       0.52      0.81      0.63       367\n",
            "           2       0.78      0.63      0.70       831\n",
            "\n",
            "    accuracy                           0.67      1607\n",
            "   macro avg       0.67      0.69      0.66      1607\n",
            "weighted avg       0.70      0.67      0.67      1607\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.75      0.62       409\n",
            "           1       0.64      0.74      0.68       367\n",
            "           2       0.90      0.67      0.77       831\n",
            "\n",
            "    accuracy                           0.70      1607\n",
            "   macro avg       0.69      0.72      0.69      1607\n",
            "weighted avg       0.75      0.70      0.71      1607\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.60      0.58       409\n",
            "           1       0.52      0.75      0.62       367\n",
            "           2       0.79      0.61      0.69       831\n",
            "\n",
            "    accuracy                           0.64      1607\n",
            "   macro avg       0.62      0.65      0.63      1607\n",
            "weighted avg       0.67      0.64      0.64      1607\n",
            "\n",
            "resnet 50 acc:  0.6689483509645302\n",
            "resnet 18 acc:  0.7025513378967019\n",
            "vgg16 acc:  0.6397013067828251\n"
          ]
        }
      ]
    }
  ]
}